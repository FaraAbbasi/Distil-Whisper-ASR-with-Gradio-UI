{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "056e2503",
   "metadata": {},
   "source": [
    "## **Automatic Speech Recognition (ASR) with Distil-Whisper**\n",
    "\n",
    "* A web interface for speech-to-text transcription using distil-whisper/distil-small.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01072a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8480418",
   "metadata": {},
   "source": [
    "* If you would like to run this code on your own machine, you can install the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736f888",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42173138",
   "metadata": {},
   "source": [
    "### **Model Initializing**\n",
    "* Creates an ASR pipeline with two key parameters:\n",
    "\n",
    "* task=\"automatic-speech-recognition\" - Specifies this is for converting speech to text\n",
    "\n",
    "* model=\"distil-whisper/distil-small.en\" - Uses a distilled version of OpenAI's Whisper model optimized for English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8783f479",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "asr = pipeline(task=\"automatic-speech-recognition\",     # Specifies this is for converting speech to text\n",
    "               model=\"distil-whisper/distil-small.en\")  # Uses a distilled version of OpenAI's Whisper model optimized for English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c07d1",
   "metadata": {},
   "source": [
    "### **Transcribing The Audio**\n",
    "* Transcribe audio file to text using speech recognition model.\n",
    "\n",
    "* Arguments: filepath: Path to audio file (e.g., .mp3, .wav)\n",
    "\n",
    "* Returns: string: Transcribed text or empty string if error occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d785f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def transcribe_speech(filepath):  \n",
    "    \n",
    "    if filepath is None:            # Check if audio file was provided\n",
    "        gr.Warning(\"No audio found, please retry.\")   \n",
    "        return \"\"                   # Return empty string on error\n",
    "        \n",
    "    output = asr(filepath,          # Gets the transcribed text from the model's output.\n",
    "      batch_size=8,                 # Process 8 chunks simultaneously (GPU optimization)\n",
    "      chunk_length_s=30,            # Split long files into 30-second segments\n",
    "      max_new_tokens=256)           # Limit output to ~200-300 words per chunk\n",
    "    return output[\"text\"]           #  Returns the transcribed text as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860bf5f3",
   "metadata": {},
   "source": [
    "### **Build a shareable app with Gradio**\n",
    "* This code creates a Gradio web interface for live microphone speech transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2e332",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr       #  Imports Gradio - a library for creating web UIs for ML models\n",
    "\n",
    "demo = gr.Blocks()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4715ff88",
   "metadata": {},
   "source": [
    "### **Microphone Transcription Interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d90ff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mic_transcribe = gr.Interface(    \n",
    "    fn=transcribe_speech,     \n",
    "    inputs=gr.Audio(sources=\"microphone\",  \n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\",\n",
    "                       lines=9),\n",
    "    allow_flagging=\"never\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf89668",
   "metadata": {},
   "source": [
    "### **File Upload Transcription Interface**"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": null,
=======
   "cell_type": "markdown",
>>>>>>> 74b6a2ee56ab31977c6fc2fcfd98c288fca7ed8c
   "id": "47bf277c",
   "metadata": {},
   "source": [
    "file_transcribe = gr.Interface(\n",
    "    fn=transcribe_speech,\n",
    "    inputs=gr.Audio(sources=\"upload\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\",\n",
    "                       lines=3),\n",
    "    allow_flagging=\"never\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd5249",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "with demo:\n",
    "    gr.TabbedInterface(\n",
    "        [mic_transcribe,\n",
    "         file_transcribe],\n",
    "        [\"Transcribe Microphone\",\n",
    "         \"Transcribe Audio File\"],\n",
    "    )\n",
    "\n",
    "demo.launch(debug = True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
